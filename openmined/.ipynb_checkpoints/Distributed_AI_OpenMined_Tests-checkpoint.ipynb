{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed model training with PyTorch's `torch.autograd` on Grid\n",
    "\n",
    "#### For Siraj's Distributed Apps Course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcateer/anaconda/envs/openmined/lib/python3.6/site-packages/h5py-2.7.1-py3.6-win-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mUPDATE: \u001b[0mConnecting to IPFS... this can take a few seconds...\n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mConnected!!! - My ID: client:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu\n",
      "all parts .... ['', 'Users', 'matthewmcateer', '.openmined']\n",
      "full path /\n",
      "full path /Users/\n",
      "full path /Users/matthewmcateer/\n",
      "full path /Users/matthewmcateer/.openmined/\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mQuerying known workers...\n",
      "\tWORKER: /p2p-circuit/ipfs/QmQabt3SWujUtai9z7GAcH2BFQv6wH7bumkd4x5oXN2obX...\u001b[31mFAIL!!!\u001b[0m\n",
      "\tWORKER: /p2p-circuit/ipfs/QmVfADpNwxjJYYzBtp5MQN27QHS94aoQGMWZiHMs2tKNAG...\u001b[32mSUCCESS!!!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mSearching for IPFS nodes - 63 found overall - 1 are OpenMined workers          \n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mFound 1 OpenMined nodes!!!\n",
      "\n",
      "Hooking into Torch...\n",
      "Overloading complete.\n"
     ]
    }
   ],
   "source": [
    "import torch # THis line should NOT be run after instantiating TorchClient\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from grid.clients.torch import TorchClient\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# instantiate client\n",
    "client = TorchClient(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to find out which nodes are connected to the Grid network. After this we can choose who to run the computations with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m ANCHOR - 1 - NAME:mpm_anchor  Ping:0.09sec  CPUs:1  CPU Load:18.2  Disk-util:49.2%  RAM-util:36.7%  GPUs:[]\u001b[0m\n",
      "COMPUTE - 2 - NAME:matthewmcateer0@gmail.com  Ping:0.05sec  CPUs:8  CPU Load:0.0  Disk-util:31.7%  RAM-util:27.9%  GPUs:[]\n"
     ]
    }
   ],
   "source": [
    "client.print_network_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']\n"
     ]
    }
   ],
   "source": [
    "compute_nodes = [x for x in client if re.match('compute:', x)]\n",
    "assert len(compute_nodes) > 0\n",
    "\n",
    "print(compute_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_nodes = compute_nodes[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laptop = compute_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Tensor Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1\n",
       " 4  4\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,1],[2,2]])\n",
    "x.send_(laptop)\n",
    "y = x * x\n",
    "y.get_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond gradient-based models\n",
    "\n",
    "Tensor computation is sufficient for training most gradient-based models, but it's not convenient for doing so when backpropagation is involved.  To solve this, we'll want to use automatic differentiation using the Variable class from `torch.autograd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some useful Grid-specific attributes that are useful for these purposes. Since we want to use autograd, we'll do so with Variables instead of tensors, but all the usual Tensor types have these attributes too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['client:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']\n",
      "id: 4082226712\n",
      "is_pointer: False\n"
     ]
    }
   ],
   "source": [
    "# Note: Variable is now a purely internal class in PyTorch v0.4.0,\n",
    "#       but Grid currently depends on v0.3.1.\n",
    "#       This will be updated as soon as possible.\n",
    "\n",
    "x = Variable(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)\n",
    "y = Variable(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(x.owners))\n",
    "print('id: {}'.format(x.id))\n",
    "print('is_pointer: {}'.format(x.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid attributes:\n",
    "- The `owners` attribute tells us where the tensor's data lives.\n",
    "- The `id` attribute is a way for each machine's instance of Grid to track which Torch objects they're holding locally, allowing different machines to request access to different objects.  This also allows each worker to know which tensors they need to perform computations on.\n",
    "- The `is_pointer` attribute tells us whether or not the object we're referring to is local or remote.  If it's local (is_pointer is False), we'll execute normal PyTorch code on it.  Otherwise, we'll send our command to the owner machine and have it perform the computation we want over there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can send our Variables like we did with the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:[torch.FloatTensor - Locations:['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']]\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']\n",
      "id: 4082226712\n",
      "is_pointer: True\n"
     ]
    }
   ],
   "source": [
    "x.send_(laptop)\n",
    "y.send_(laptop)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(x.owners))\n",
    "print('id: {}'.format(x.id))\n",
    "print('is_pointer: {}'.format(x.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location is different (we're now using a compute node with a different worker ID), and the `is_pointer` attribute changed to True.  The data is no longer on this machine; it's now on the worker machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll demonstrate some remote computation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = x.matmul(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the result's attributes like we did for `x` and `y` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:[torch.FloatTensor - Locations:['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']]\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['compute:QmNir4vTCoVP5pipEypUCjUtaiNXQ1SL64YWX8EMyfytUu']\n",
      "id: 2131795\n",
      "is_pointer: True\n"
     ]
    }
   ],
   "source": [
    "print(z)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(z.owners))\n",
    "print('id: {}'.format(z.id))\n",
    "print('is_pointer: {}'.format(z.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is this notable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't have to change anything in our PyTorch code.  The command `matmul` is identical to the normal PyTorch command, but the computation is being performed elsewhere.\n",
    "\n",
    "This example was also NOT cherry-picked; theoretically any method or function that inputs and outputs Tensor/Variable objects can be used in this exact same way, as long as those objects are stored somewhere on Grid and we have a local pointer to those objects.\n",
    "\n",
    "Although the computation result is on the other machine, we still have access to a local pointer for the Variable.  We can use that pointer in future computations, chaining together commands for remote machines without having to retrieve and send the underlying data between each command. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_sum = z.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Variables so that we can take advantage of autograd.  Let's make sure that works, by taking the derivative of `z_sum` with respect to `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_sum.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives with respect to `x` and `y` are now stored in `x.grad` and `y.grad`, but we'll need to retrieve `x` and `y` to access those.  That's okay for this use case, since we're not concerned about data privacy right now.  Figuring out how to call `get_` on the grad itself would be another useful contribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2  4\n",
      " 2  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.get_()\n",
    "y.get_()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now computed derivatives on a remote machine, and we did so interactively with a dynamic computation graph over a peer-to-peer network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with distributed gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, IPFS has some limitations around how much data can be transferred in one block.  They've introduced a sharding mechanism to get around this ([see here](https://github.com/ipfs/go-ipfs/pull/3042)), but it's not currently being used in Grid. \n",
    "\n",
    "We'll use Data with relatively low dimensionality -- the [Boston housing prices dataset](https://www.kaggle.com/c/boston-housing/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "mean = X.mean(0, keepdim=True)\n",
    "dev = X.std(0, keepdim=True)\n",
    "mean[:, 3] = 0. # the feature at column 3 is binary,\n",
    "dev[:, 3] = 1.  # so I'd rather not standardize it\n",
    "X = (X - mean) / dev\n",
    "X_test = (X_test - mean) / dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "batch_size = 8\n",
    "learning_rate = .01\n",
    "epochs = 5\n",
    "update_master_every = 3\n",
    "\n",
    "# architecture\n",
    "input_shape = X.shape[1]\n",
    "first_neurons = 64\n",
    "second_neurons = 32\n",
    "try: # will work for multivariate regression tasks too\n",
    "    dep_vars = y.size(1)\n",
    "except RuntimeError:\n",
    "    dep_vars = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch utilities for supplying data to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = TensorDataset(X, y)\n",
    "test = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_load = DataLoader(train, batch_size = 8, drop_last=True)\n",
    "ts_load = DataLoader(test, batch_size = 8, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocating training batches to each worker\n",
    "\n",
    "Once we send batches out to participating workers, they won't need to move around for the rest of training -- they'll only be sharing the model.  Our client machine will play the role of Parameter Server.  This is known as \"data parallelism\" (as opposed to \"model parallelism\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 15.8 ms, total: 240 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "allocated = []\n",
    "\n",
    "for (ix, (x_i, y_i)) in enumerate(tr_load):\n",
    "    x_i = Variable(x_i, requires_grad = True)\n",
    "    y_i = Variable(y_i, requires_grad = True)\n",
    "    x_i.send_(compute_nodes[ix % len(compute_nodes)])\n",
    "    y_i.send_(compute_nodes[ix % len(compute_nodes)])\n",
    "    allocated.append((x_i, y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allocated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters initialized.\n"
     ]
    }
   ],
   "source": [
    "W_0 = nn.Parameter(torch.FloatTensor(input_shape, first_neurons))\n",
    "W_1 = nn.Parameter(torch.FloatTensor(first_neurons, second_neurons))\n",
    "W_2 = nn.Parameter(torch.FloatTensor(second_neurons, dep_vars))\n",
    "\n",
    "# initialize properly\n",
    "relu_gain = nn.init.calculate_gain('relu')\n",
    "lin_gain = nn.init.calculate_gain('linear')\n",
    "\n",
    "nn.init.xavier_normal(W_0, gain=relu_gain)\n",
    "nn.init.xavier_normal(W_1, gain=relu_gain)\n",
    "nn.init.xavier_normal(W_2, gain=lin_gain)\n",
    "\n",
    "print('Network parameters initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    \"\"\"Rectified linear activation\"\"\"\n",
    "    return torch.clamp(x, min=0.)\n",
    "\n",
    "def linear(x, w):\n",
    "    \"\"\"Linear transformation of x by w\"\"\"\n",
    "    return torch.matmul(x,w)\n",
    "\n",
    "def mse(y_hat, y_true):\n",
    "    \"\"\"Mean-squared error\"\"\"\n",
    "    return torch.mean(torch.pow(y_hat - y_true, 2), dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient update helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_grads(grads):\n",
    "    \"\"\"Average a sequence of gradients\"\"\"\n",
    "    return torch.mean(torch.cat(grads))\n",
    "\n",
    "def update_params(param, grad, alpha):\n",
    "    \"\"\"Update parameter tensor with standard mini-batch gradient descent\"\"\"\n",
    "    return param - alpha * grad\n",
    "\n",
    "def reset_flags(param):\n",
    "    \"\"\"Resets flags for a Parameter that's experienced an in-place operation\"\"\"\n",
    "    param.requires_grad = True\n",
    "    param.volatile = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done!\n",
      "Epoch 2 done!\n",
      "Epoch 3 done!\n",
      "Epoch 4 done!\n",
      "Epoch 5 done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient buffers\n",
    "W_0_grads = []\n",
    "W_1_grads = []\n",
    "W_2_grads = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Loop over distributed batches\n",
    "    for ix, (x_i, y_i) in enumerate(allocated):\n",
    "        # Broadcast current weights to workers\n",
    "        W_0_clones = [W_0.clone().send_(node) for node in compute_nodes]\n",
    "        W_1_clones = [W_1.clone().send_(node) for node in compute_nodes]\n",
    "        W_2_clones = [W_2.clone().send_(node) for node in compute_nodes]\n",
    "\n",
    "        # Pull pointers from clone list\n",
    "        W_0_tmp = W_0_clones[ix % len(compute_nodes)]\n",
    "        W_1_tmp = W_1_clones[ix % len(compute_nodes)]\n",
    "        W_2_tmp = W_2_clones[ix % len(compute_nodes)]\n",
    "\n",
    "        # Forward pass\n",
    "        act_0 = relu(linear(x_i, W_0_tmp))\n",
    "        act_1 = relu(linear(act_0, W_1_tmp))\n",
    "        y_hat = linear(act_1, W_2_tmp).view(-1)\n",
    "\n",
    "        # Calculate MSE loss and perform backprop\n",
    "        y_i = y_i.type_as(y_hat) # type-safety\n",
    "        loss = mse(y_hat, y_i)\n",
    "        loss.backward()\n",
    "\n",
    "        # Recall parameters\n",
    "        W_0_tmp.get_()\n",
    "        W_1_tmp.get_()\n",
    "        W_2_tmp.get_()\n",
    "\n",
    "        # Store parameter grads\n",
    "        W_0_grads.append(W_0_tmp.grad)\n",
    "        W_1_grads.append(W_1_tmp.grad)\n",
    "        W_2_grads.append(W_2_tmp.grad)\n",
    "\n",
    "        # Update master parameters\n",
    "        if ix % update_master_every == 0:\n",
    "            W_0_grad = average_grads(W_0_grads)\n",
    "            W_1_grad = average_grads(W_1_grads)\n",
    "            W_2_grad = average_grads(W_2_grads)\n",
    "\n",
    "            W_0 = update_params(W_0, W_0_grad, alpha=learning_rate)\n",
    "            W_1 = update_params(W_1, W_1_grad, alpha=learning_rate)\n",
    "            W_2 = update_params(W_2, W_2_grad, alpha=learning_rate)\n",
    "\n",
    "            # We've overridden Variables in-place, which breaks the computation graph internally\n",
    "            # This is intentional, but this needs to be cleaned up a bit to be able to keep going\n",
    "            reset_flags(W_0)\n",
    "            reset_flags(W_1)\n",
    "            reset_flags(W_2)\n",
    "            \n",
    "            # Cleaning out parameter server grad buffers\n",
    "            W_0_grads = []\n",
    "            W_1_grads = []\n",
    "            W_2_grads = []\n",
    "            \n",
    "\n",
    "    print(\"Epoch {} done!\".format(epoch + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
